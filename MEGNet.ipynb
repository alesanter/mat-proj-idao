{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Для работы в Google Colab\n","_______________"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"eTlSpGc8CMxj"},"outputs":[],"source":["# !pip uninstall -y numpy\n","# !pip uninstall -y setuptools\n","\n","# !pip install setuptools\n","# !pip install numpy"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17638,"status":"ok","timestamp":1711318413132,"user":{"displayName":"Kirill Sokolsky","userId":"02716003461436907478"},"user_tz":-180},"id":"f_nrvXPcCP87","outputId":"68a39344-44d1-4ffa-f48f-3d54a55050ce"},"outputs":[],"source":["# !wget https://github.com/HSE-LAMBDA/IDAO-2022/archive/refs/heads/main.zip\n","# !unzip main.zip\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","\n","# %cd /content/drive/MyDrive/DLS/IDAO_2022/\n","\n","# !tar -C \"/IDAO_2022/data\" -xzvf /content/drive/MyDrive/IDAO_2022/data/dichalcogenides_private.tar.gz\n","# !tar -C \"/IDAO_2022/data\" -xzvf /content/drive/MyDrive/IDAO_2022/data/dichalcogenides_public.tar.gz"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QopFYQlACR-k"},"outputs":[],"source":["# !pip install megnet\n","# !pip install pymatgen"]},{"cell_type":"markdown","metadata":{},"source":["_________________"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":15362,"status":"ok","timestamp":1711318446241,"user":{"displayName":"Kirill Sokolsky","userId":"02716003461436907478"},"user_tz":-180},"id":"aXtQdqbSCTG9"},"outputs":[],"source":["import yaml\n","import json\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","\n","from pathlib import Path\n","from pymatgen.core import Structure\n","from sklearn.model_selection import train_test_split\n","from megnet.models import MEGNetModel\n","from megnet.data.crystal import CrystalGraph"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1711318455075,"user":{"displayName":"Kirill Sokolsky","userId":"02716003461436907478"},"user_tz":-180},"id":"CxQFmHfkCVfj"},"outputs":[],"source":["def cation_vacancy(pymatgen_dict: Structure,\n","                   coord_a: float = 0.041667,\n","                   coord_b: float = 0.083333):\n","    vacancy_coords_list = []\n","    for i in range(8):\n","        for j in range(8):\n","            vacancy_coords_list.append([coord_a + 0.125 * i,\n","                                        coord_b + 0.125 * j,\n","                                        0.25])\n","    for i in pymatgen_dict:\n","        coords = [round(float(i.a), 6), round(float(i.b), 6), round(float(i.c), 6)]\n","        if coords in vacancy_coords_list:\n","            vacancy_coords_list.remove(coords)\n","\n","    for i in range(len(vacancy_coords_list)):\n","        pymatgen_dict.append('Cr', vacancy_coords_list[i], False)\n","    return pymatgen_dict\n","\n","\n","def anion_vacancy(pymatgen_dict: Structure,\n","                  coord_a: float = 0.083333,\n","                  coord_b: float = 0.041667,\n","                  coord_c: float = 0.144826,\n","                  first_second_layer_distance: float = 0.210348):\n","    vacancy_coords_list = []\n","    coords_list_1_layer = []\n","    coords_list_2_layer = []\n","    # 1st anion layer\n","    for i in range(8):\n","        for j in range(8):\n","            coords_list_1_layer.append([coord_a + 0.125 * i,\n","                                        coord_b + 0.125 * j,\n","                                        coord_c])\n","    # 2nd anion layer\n","    for i in range(8):\n","        for j in range(8):\n","            coords_list_2_layer.append([coord_a + 0.125 * i,\n","                                        coord_b + 0.125 * j,\n","                                        coord_c + first_second_layer_distance])\n","    # 1st anion layer\n","    for i in pymatgen_dict:\n","        coords = [round(float(i.a), 6), round(float(i.b), 6), round(float(i.c), 6)]\n","        if coords in coords_list_1_layer:\n","            coords_list_1_layer.remove(coords)\n","\n","    # 2nd anion layer\n","    for i in pymatgen_dict:\n","        coords = [round(float(i.a), 6), round(float(i.b), 6), round(float(i.c), 6)]\n","        if coords in coords_list_2_layer:\n","            coords_list_2_layer.remove(coords)\n","\n","    # 1st anion layer\n","    for i in range(len(coords_list_1_layer)):\n","        pymatgen_dict.append('O', coords_list_1_layer[i], False)\n","\n","    # 2nd anion layer\n","    for i in range(len(coords_list_2_layer)):\n","        pymatgen_dict.append('O', coords_list_2_layer[i], False)\n","\n","    return pymatgen_dict\n","\n","\n","def data_preprocessing(pymatgen_dict: Structure, cation: int = 0, anion: int = 0):\n","    formula = str(pymatgen_dict.formula).split(' ')\n","    for i in formula:\n","        if 'Mo' in i or 'W' in i:\n","            cation += int(i.lstrip('MoW'))\n","        if 'S' in i or 'Se' in i:\n","            anion += int(i.lstrip('SeS'))\n","    if cation < 64:\n","        pymatgen_dict = cation_vacancy(pymatgen_dict)\n","    if anion < 128:\n","        pymatgen_dict = anion_vacancy(pymatgen_dict)\n","    return pymatgen_dict\n","\n","\n","def read_pymatgen_dict(file):\n","    with open(file, \"r\") as f:\n","        d = json.load(f)\n","    return data_preprocessing(Structure.from_dict(d))\n","\n","\n","def energy_within_threshold(prediction, target):\n","    # compute absolute error on energy per system.\n","    # then count the no. of systems where max energy error is < 0.02.\n","    e_thresh = 0.02\n","    error_energy = tf.math.abs(target - prediction)\n","\n","    success = tf.math.count_nonzero(error_energy < e_thresh)\n","    total = tf.size(target)\n","    return success / tf.cast(total, tf.int64)\n","\n","def prepare_dataset(dataset_path):\n","    dataset_path = Path(dataset_path)\n","    targets = pd.read_csv(dataset_path / \"targets.csv\", index_col=0)\n","    struct = {\n","        item.name.strip(\".json\"): read_pymatgen_dict(item)\n","        for item in (dataset_path / \"structures\").iterdir()\n","    }\n","\n","    data = pd.DataFrame(columns=[\"structures\"], index=struct.keys())\n","    data = data.assign(structures=struct.values(), targets=targets)\n","\n","    return train_test_split(data, test_size=0.25, random_state=666)\n","\n","\n","def prepare_model(cutoff, lr):\n","    nfeat_bond = 100\n","    r_cutoff = cutoff\n","    gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n","    gaussian_width = 0.8\n","\n","    return MEGNetModel(\n","        graph_converter=CrystalGraph(cutoff=r_cutoff),\n","        centers=gaussian_centers,\n","        width=gaussian_width,\n","        loss=[\"MAE\"],\n","        npass=2,\n","        lr=lr,\n","        metrics=energy_within_threshold\n","    )\n","\n","\n","def main_to_train(config):\n","    train, test = prepare_dataset(config[\"datapath\"])\n","    model = prepare_model(\n","        float(config[\"model\"][\"cutoff\"]),\n","        float(config[\"model\"][\"lr\"]),\n","    )\n","\n","    model.train(\n","        train.structures,\n","        train.targets,\n","        validation_structures=test.structures,\n","        validation_targets=test.targets,\n","        epochs=int(config[\"model\"][\"epochs\"]),\n","        batch_size=int(config[\"model\"][\"batch_size\"])\n","    )\n","    return model\n","\n","\n","config_path = './dataset/config.yaml'\n","\n","if __name__ == \"__main__\":\n","    with open(config_path) as file:\n","        config = yaml.safe_load(file)\n","    main_to_train(config)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["config_path = './dataset/config.yaml'"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOEhDjp9ChkU","outputId":"d57887a5-410a-4a70-e04a-dc08c5481a03"},"outputs":[{"ename":"TypeError","evalue":"Trainer.compile() got an unexpected keyword argument 'sample_weight_mode'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_path) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m     config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmain_to_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[7], line 126\u001b[0m, in \u001b[0;36mmain_to_train\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain_to_train\u001b[39m(config):\n\u001b[0;32m    125\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m prepare_dataset(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatapath\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 126\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcutoff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    132\u001b[0m         train\u001b[38;5;241m.\u001b[39mstructures,\n\u001b[0;32m    133\u001b[0m         train\u001b[38;5;241m.\u001b[39mtargets,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    138\u001b[0m     )\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n","Cell \u001b[1;32mIn[7], line 113\u001b[0m, in \u001b[0;36mprepare_model\u001b[1;34m(cutoff, lr)\u001b[0m\n\u001b[0;32m    110\u001b[0m gaussian_centers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, r_cutoff \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, nfeat_bond)\n\u001b[0;32m    111\u001b[0m gaussian_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMEGNetModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_converter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCrystalGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_cutoff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgaussian_centers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgaussian_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnpass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menergy_within_threshold\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\neutron\\Desktop\\mat-proj-idao\\venv\\Lib\\site-packages\\megnet\\models\\megnet.py:129\u001b[0m, in \u001b[0;36mMEGNetModel.__init__\u001b[1;34m(self, nfeat_edge, nfeat_global, nfeat_node, nblocks, lr, n1, n2, n3, nvocal, embedding_dim, nbvocal, bond_embedding_dim, ngvocal, global_embedding_dim, npass, ntarget, act, is_classification, loss, metrics, l2_coef, dropout, graph_converter, target_scaler, optimizer_kwargs, dropout_on_predict, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     opt_params\u001b[38;5;241m.\u001b[39mupdate(optimizer_kwargs)\n\u001b[1;32m--> 129\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_converter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     graph_converter \u001b[38;5;241m=\u001b[39m CrystalGraph(cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, bond_converter\u001b[38;5;241m=\u001b[39mGaussianDistance(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m0.5\u001b[39m))\n","File \u001b[1;32mc:\\Users\\neutron\\Desktop\\mat-proj-idao\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\neutron\\Desktop\\mat-proj-idao\\venv\\Lib\\site-packages\\keras\\src\\utils\\tracking.py:28\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mTypeError\u001b[0m: Trainer.compile() got an unexpected keyword argument 'sample_weight_mode'"]}],"source":["if __name__ == \"__main__\":\n","    with open(config_path) as file:\n","        config = yaml.safe_load(file)\n","    main_to_train(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDsTKpxWCmOk"},"outputs":[],"source":["def main_to_predict(config):\n","    train, test = prepare_dataset(config[\"datapath\"])\n","\n","    model = prepare_model(\n","        float(config[\"model\"][\"cutoff\"]), float(config[\"model\"][\"lr\"])\n","    )\n","    #? model.load_weights(config['checkpoint_path'])\n","\n","    # dataset_path = Path(config['test_datapath'])\n","    # struct = {item.name.strip('.json'): read_pymatgen_dict(item) for item in (dataset_path/'structures').iterdir()}\n","    struct = test\n","\n","    # private_test = pd.DataFrame(columns=['id', 'structures'], index=struct.keys())\n","    # private_test = private_test.assign(structures=struct.values())\n","    # private_test = private_test.assign(predictions=model.predict_structures(private_test.structures))\n","    # private_test[['predictions']].to_csv('./submission111.csv', index_label='id')\n","\n","    private_test = pd.DataFrame(columns=['id', 'structures'], index=struct.index.values.tolist())\n","    private_test = private_test.assign(structures=struct.structures.values.tolist())\n","    private_test = private_test.assign(predictions=model.predict_structures(private_test.structures))\n","    private_test[['predictions']].to_csv('./submission111.csv', index_label='id')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yQxVGWHCmtL"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    with open(\"config.yaml\") as file:\n","        config = yaml.safe_load(file)\n","    main_to_predict(config)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPZY6nCyKY/p1BcGYbhVCdU","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
